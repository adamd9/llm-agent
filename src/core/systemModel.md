# Updated System Model of the LLM Agent

This document describes the internal architecture and operational flow of the LLM Agent. It is an amalgamation of the original detailed architecture and recent insights derived from memory data. The model has been refined to reflect current operational details, especially regarding memory handling, reflection, and contextual interactions.

## 1. Core Architecture Overview

The agent is built upon a modular, layered architecture with three primary components:

*   **Ego Layer (`src/core/ego/`)**:  
    - The central orchestrator handling natural language understanding, task management, identity & personality, and user interaction.  
    - Drives the main execution loop, including planning, execution, evaluation, and reflection.  
    - Stores user messages, execution results, and reflection insights in short-term memory; retrieves relevant memories (short-term & long-term) via LLM-based relevance filtering and summarization.  
    - Emits status, debug, system, and subsystem events for transparency and debugging.  
    - Performs reflection after each response to analyze recent interactions and store lessons/insights into long-term memory, enhancing adaptability.  

*   **Coordinator Layer (`src/core/coordinator/`)**:  
    - Executes plans generated by the Ego’s planner.  
    - Coordinates step-by-step execution, invoking tools via `MCPToolManager`.  
    - Supports re-planning if tools request replanning or if execution results suggest adjustments.  
    - Emits subsystem messages with execution status or errors.

*   **Tool Layer (`src/mcp/`, `src/tools/`, `data/tools/`, `data/mcp-servers/`, `data/remote-mcp-servers/`)**:  
    - Provides the agent's capabilities via tools, which may be local scripts, local MCP servers, or remote MCP servers accessed via SDK.  
    - Tools follow a standard interface with `name`, `description`, and `execute()` method.  
    - `MCPToolManager` acts as the central registry and loader for all tools, supporting dynamic loading from local files, local MCP servers (via `MCPClient`), and remote MCP servers (via SDK).  

*Communication between layers is achieved through interfaces, event system (`sharedEventEmitter`), and standard protocols.*

## 2. Memory System

The Memory subsystem has been significantly refined with recent insights:

* **Storage Locations**:  
    - **Short-term memory (`short_term.txt`)**: Session-based, stores recent interactions, commands, intermediate results, tagged explicitly with module identifiers and timestamps. Content is appended with `<MEMORY>` tags, including context, module, and timestamp.  
    - **Long-term memory (`long_term.txt`)**: Persistent store for contextual info, summaries, and tags. When storing, an LLM analyzes content to generate summaries and relevance tags (`MEMORY_ANALYSIS_PROMPT`). When retrieving, relevance filtering is performed using an LLM-based relevance filtering prompt (`MEMORY_RETRIEVAL_PROMPT`).  

* **Memory Analysis & Categorization**:  
    - Recent interactions like consolidation commands are explicitly stored with module tags and timestamps.  
    - Memory analysis (summarization, tagging) is performed via LLM, and insights are stored in long-term memory, which informs future planning and responses.  
    - Memory retrieval is relevance-based, considering recent short-term memory as context, and is transparently logged via subsystem events.

* **Memory Operations**:  
    - Emission of `subsystemMessage` events during memory retrieval, analysis, and storage for transparency.

## 3. System Flow & Operational Loop

The core operation is an iterative loop involving:

1. **User Input**: Incoming message via WebSocket or other interface.  
2. **Ego Processing (`Ego.processMessage`)**:  
    - Stores message in short-term memory with module tags.  
    - Retrieves relevant short-term and long-term memories via LLM relevance filtering and summarization.  
    - Creates an `enrichedMessage` containing user query, context, memories, and capabilities.  
3. **Planning (`Planner`)**:  
    - Builds a detailed prompt including `enrichedMessage`, available tools, short-term and relevant long-term memories.  
    - Calls the OpenAI API (with `PLAN_SCHEMA`) to generate a structured, JSON plan specifying steps and tools.  
    - Validates plan tools against available tools.  
    - Emits subsystem message with planning details.  
4. **Execution (`Coordinator`)**:  
    - Executes plan step-by-step, invoking tools via `MCPToolManager`.  
    - Handles errors, retries, or replans as necessary.  
    - Emits subsystem messages with execution results or errors.  
5. **Evaluation (`Evaluator`)**:  
    - Calls the LLM (with `EVALUATION_SCHEMA`) to compare execution results against the original user intent.  
    - Receives a success score, analysis, and recommendations.  
6. **Decision & Retry**:  
    - If success score exceeds threshold (e.g., 80%) or max retries reached, proceed.  
    - If low score and retries remain, generate reflection prompts to analyze evaluation feedback, store lessons, and update context.  
7. **Response Generation (`Ego.handleBubble`)**:  
    - Uses LLM to generate natural language reply based on final results or errors.  
    - Stores the response in memory.  
    - Initiates reflection process after response, analyzing recent interactions and insights, storing lessons in long-term memory.  
8. **Output**: Response sent back to user, and process repeats if needed.

Throughout, status updates, debug info, and internal insights are emitted via `sharedEventEmitter`.

## 4. Reflection & Memory Enrichment

- Reflection prompts (`reflection-prompts.js`) analyze the latest short-term memory and relevant long-term memory to generate JSON insights, lessons, follow-up questions, and directives.  
- These insights are stored in long-term memory, enhancing the agent’s adaptive capabilities.  
- Reflection occurs after each response, including consolidation commands, as observed in memory logs.  
- Reflection results include lessons learned, which inform future planning and decision-making.

## 5. Tools & Communication

- **`MCPToolManager`**: Registry and loader for local scripts, MCP servers, and remote MCP servers.  
- **`MCPClient`**: Handles communication with MCP servers, supports streaming responses for remote servers.  
- **Tools**: All tools conform to a uniform interface with `name`, `description`, and `execute()` method.  
- **Remote tools**: Accessed via SDK or local MCP servers, with communication managed through `MCPClient`.

## 6. Event System

- Key events include: `assistantResponse`, `debugResponse`, `systemStatusMessage`, `subsystemMessage`, `systemError`, and `bubble`.  
- These provide transparency, debugging, and insights into internal processes, especially memory operations, planning, execution, and reflection.

## 7. Configuration & Overrides

- Prompts can be overridden via files in `data/prompts/<module>/<PROMPT_NAME>.txt`.  
- Environment variables (`LLM_AGENT_DATA_DIR`, API keys) control data storage and API access.  
- Tool configurations are in `data/mcp-servers/` and `data/remote-mcp-servers/`.

## 8. Recent Memory Insights & Operational Enhancements

- Memory analysis via LLM (summaries, tags) integrated into long-term storage.  
- Memory relevance filtering incorporates recent short-term context, providing richer, contextual retrieval.  
- Reflection after each response improves agent adaptability, with lessons stored for future cycles.  
- Explicit handling of commands like consolidation, consolidation feedback, and memory analysis has been integrated into operational flow.

---

## 9. Contradictions & Preferences

- The current detailed architecture has been refined with recent memory data.  
- Memory analysis, relevance-based retrieval, and reflection have been explicitly incorporated into the operational flow.  
- No contradictions were found; newer insights about explicit memory tagging, reflection, and memory analysis are now embedded.

---

This completes the comprehensive update of the technical model, integrating recent memory-driven insights to accurately reflect the current system operations, components, and operational flow.