# Updated System Model of the LLM Agent

This document describes the internal architecture and operational flow of the LLM Agent. It is an amalgamation of the original detailed architecture and recent insights derived from memory data. The model has been refined to reflect current operational details, especially regarding memory handling, reflection, and contextual interactions.

## 1. Core Architecture Overview

The agent is built upon a modular, layered architecture with three primary components:

*   **Ego Layer (`src/core/ego/`)**:  
    - The central orchestrator handling natural language understanding, task management, identity & personality, and user interaction.  
    - Drives the main execution loop, including planning, execution, evaluation, and reflection.  
    - Stores user messages, execution results, and reflection insights in short-term memory; retrieves relevant memories (short-term & long-term) via LLM-based relevance filtering and summarization.  
    - Emits status, debug, system, and subsystem events for transparency and debugging.  
    - After each assistant response the task planner triggers the `reflection` tool, which performs a lightweight analysis of recent interactions and stores lessons/insights into long-term memory.  
    - Explicitly tags memory entries with module identifiers and timestamps, supporting detailed memory analysis and consolidation commands.

*   **Coordinator Layer (`src/core/coordinator/`)**:  
    - Executes plans generated by the Ego's planner.  
    - Coordinates step-by-step execution, invoking tools via `MCPToolManager`.  
    - Supports re-planning if tools request replanning or if execution results suggest adjustments.  
    - When a replan is triggered, stores the updated plan in short-term memory and logs the transition details.  
    - Emits subsystem messages with execution status or errors.

*   **Tool Layer (`src/mcp/`, `src/tools/`, `data/tools/`, `data/mcp-servers/`, `data/remote-mcp-servers/`)**:  
    - Provides the agent's capabilities via tools, which may be local scripts, local MCP servers, or remote MCP servers accessed via SDK.  
    - Tools follow a standard interface with `name`, `description`, and `execute()` method.  
    - `MCPToolManager` acts as the central registry and loader for all tools, supporting dynamic loading from local files, local MCP servers (via `MCPClient`), and remote MCP servers (via SDK).  

*Communication between layers is achieved through interfaces, event system (`sharedEventEmitter`), and standard protocols.*

## 2. Memory System

The Memory subsystem has been significantly refined with recent insights:

* **Storage Locations**:  
    - **Short-term memory (`short_term.txt`)**: Session-based, stores recent interactions, commands, intermediate results, tagged explicitly with module identifiers and timestamps. Content is appended with `<MEMORY>` tags, including context, module, and timestamp. Recent interactions like consolidation commands are stored as explicit commands with tags and timestamps, enabling targeted retrieval and analysis.  
    - **Long-term memory (`long_term.txt`)**: Persistent store for contextual info, summaries, and tags. When storing, an LLM analyzes content to generate summaries and relevance tags (`MEMORY_ANALYSIS_PROMPT`). When retrieving, relevance filtering is performed using an LLM-based relevance filtering prompt (`MEMORY_RETRIEVAL_PROMPT`).  

* **Memory Analysis & Categorization**:  
    - Recent interactions like consolidation commands are explicitly stored with module tags and timestamps.  
    - Memory analysis (summarization, tagging) is performed via LLM, and insights are stored in long-term memory, which informs future planning and responses.  
    - Commands such as memory consolidation, consolidation feedback, and memory analysis are explicitly recorded in memory logs, facilitating targeted queries and operations.  
    - Reflection prompts analyze the latest short-term memory and relevant long-term memory to generate JSON insights, lessons, follow-up questions, and directives.  
    - Reflection results, including lessons learned, are stored in long-term memory, feeding into the agent’s adaptive capabilities.

* **Memory Operations**:  
    - Emission of `subsystemMessage` events during memory retrieval, analysis, and storage for transparency.  
    - Memory data—including commands and their results—are available for analysis during reflection and consolidation commands, ensuring continuous learning and memory management.

## 3. System Flow & Operational Loop

The core operation is an iterative loop involving:

1. **User Input**: Incoming message via WebSocket or other interface.  
2. **Ego Processing (`Ego.processMessage`)**:  
    - Stores message in short-term memory with module tags.  
    - Retrieves relevant short-term and long-term memories via LLM relevance filtering and summarization.  
    - Creates an `enrichedMessage` containing user query, context, memories, and capabilities.  
3. **Planning (`Planner`)**:  
    - Builds a detailed prompt including `enrichedMessage`, available tools, short-term and relevant long-term memories.  
    - Calls the OpenAI API (with `PLAN_SCHEMA`) to generate a structured, JSON plan specifying steps and tools.  
    - Validates plan tools against available tools.  
    - Emits subsystem message with planning details.  
4. **Execution (`Coordinator`)**:  
    - Executes plan step-by-step, invoking tools via `MCPToolManager`.  
    - Handles errors, retries, or replans as necessary.  
    - Emits subsystem messages with execution results or errors.  
5. **DmemoryMaintenance Memory Maintenance (`memoryMaintenance` tool)**:  
    - Periodically or when explicitly scheduled, the planner invokes the heavy-weight `memoryMaintenance` tool.  
    - It consolidates long-term memory, prunes low-value items, and can run intensive evaluations of recent execution results where needed.  
6. **Decision & Retry**:  
    - If success score exceeds threshold (e.g., 80%) or max retries reached, proceed.  
    - If low score and retries remain, generate reflection prompts to analyze evaluation feedback, store lessons, and update context.  
7. **Response Generation (`Ego.handleBubble`)**:  
    - Uses LLM to transform internal tool execution results into natural, personality-driven responses to the user.  
    - Processes structured execution results which may be in one of three formats:
      - Error messages ("Error: [error message]")
      - Tool output content (plain text or JSON)
      - Complex objects with fields like type, response, and enriched_message
    - Generates responses that could be statements, summaries from results, or questions for the user.
    - The response output is formatted as JSON with 'chat' (brief 1-2 sentence response) and 'canvas' (detailed markdown content) fields.
    - Stores the response in memory.
    - Initiates reflection process after response, analyzing recent interactions and insights, storing lessons in long-term memory.  
8. **Output**: Response sent back to user, and process repeats if needed.

Throughout, status updates, debug info, and internal insights are emitted via `sharedEventEmitter`.

## 4. Reflection & Memory Enrichment

- The `reflection` tool analyzes the latest short-term memory and relevant long-term memory to generate JSON insights, lessons, follow-up questions, and directives.  
- These insights are stored in long-term memory, enhancing the agent’s adaptive capabilities.  
- Reflection occurs after each assistant response via the `reflection` tool, including during consolidation commands.  
- Reflection results include lessons learned, which inform future planning and decision-making.

## 5. Tools & Communication

- **`MCPToolManager`**: Registry and loader for local scripts, MCP servers, and remote MCP servers.  
- **`MCPClient`**: Handles communication with MCP servers, supports streaming responses for remote servers.  
- **Tools**: All tools conform to a uniform interface with `name`, `description`, and `execute()` method.  
- **Remote tools**: Accessed via SDK or local MCP servers, with communication managed through `MCPClient`.
- **`planUpdater` Tool**: Special tool for updating plans based on results of prior steps.
  - Validates that any tools in the updated plan actually exist in the system.
  - Prevents creation of plans with non-existent tools.
  - Returns a `replan` status when plan updates are needed, which triggers the coordinator to execute the updated plan.

## 6. Event System

- Key events include: `assistantResponse`, `debugResponse`, `systemStatusMessage`, `subsystemMessage`, `systemError`, and `bubble`.  
- These provide transparency, debugging, and insights into internal processes, especially memory operations, planning, execution, and reflection.

## 7. Configuration & Overrides

- Prompts can be overridden via files in `data/prompts/<module>/<PROMPT_NAME>.txt`.  
- Environment variables (`LLM_AGENT_DATA_DIR`, `API keys`) control data storage and API access.  
- Tool configurations are in `data/mcp-servers/` and `data/remote-mcp-servers/`.  
- Token limits are enforced via the `tokenLimit` setting (default: 10000 tokens). If a request exceeds this limit, an error is emitted to the error subsystem and the request is rejected.

## 8. Recent Memory Insights & Operational Enhancements

- Memory analysis via LLM (summaries, tags) integrated into long-term storage.  
- Memory relevance filtering incorporates recent short-term context, providing richer, contextual retrieval.  
- Reflection after each response improves agent adaptability, with lessons stored for future cycles.  
- Explicit handling of commands like consolidation, consolidation feedback, and memory analysis has been integrated into operational flow.  
- Commands such as "consolidate" are explicitly stored as memory entries with module tags and timestamps, allowing targeted retrieval and processing.

---

## 9. Contradictions & Preferences

- The current detailed architecture has been refined with recent memory data.  
- Memory analysis, relevance-based retrieval, and reflection have been explicitly incorporated into the operational flow.  
- No contradictions were found; newer insights about explicit memory tagging, reflection, and memory analysis are now embedded.

---

This completes the comprehensive update of the technical model, integrating recent memory-driven insights to accurately reflect the current system operations, components, and operational flow.