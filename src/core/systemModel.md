# Updated System Model of the LLM Agent

This document describes the internal architecture and operational flow of the LLM Agent. It is an amalgamation of the original detailed architecture and recent insights derived from memory data. The model has been refined to reflect current operational details, especially regarding memory handling, reflection, and contextual interactions.

## 1. Core Architecture Overview

The agent is built upon a modular, layered architecture with three primary components:

*   **Ego Layer (`src/core/ego/`)**:  
    - The central orchestrator handling natural language understanding, task management, identity & personality, and user interaction.  
    - Drives the main execution loop, including planning, execution, evaluation, and reflection.  
    - Stores user messages, execution results, and reflection insights in short-term memory; retrieves relevant memories (short-term & long-term) via LLM-based relevance filtering and summarization.  
    - Emits status, debug, system, and subsystem events for transparency and debugging with descriptive titles that include function names for LLM responses and tool names for tool executions and errors.  
    - After each assistant response the task planner triggers the `reflection` tool, which performs a lightweight analysis of recent interactions and stores lessons/insights into long-term memory.  
    - Explicitly tags memory entries with module identifiers and timestamps, supporting detailed memory analysis and consolidation commands.

*   **Coordinator Layer (`src/core/coordinator/`)**:  
    - Executes strategies generated by the Ego's strategic planner using a REACT (Reason + Act) approach.  
    - Implements strategy-guided execution with iterative step planning and evaluation through the `executeREACT` function.  
    - Uses complexity assessment (Simple/Moderate/Complex) from the strategy to determine execution flow.  
    - For each step, dynamically plans the next action based on progress and previous results using `planNextStep`.  
    - Enforces iteration limits (`maxREACTIterations`, default: 10) to prevent infinite loops, with a hard break when the limit is reached.  
    - Evaluates each step against the strategy's success criteria using `evaluateStep` to determine completion.  
    - Handles tool execution with proper parameter mapping, especially for tools like `question` that require specific parameter formats.  
    - Maintains a history of previous steps, results, and evaluations to inform future planning.  
    - Emits subsystem messages with execution status, planned steps, tool executions, and evaluations.  
    - For simple tasks, may complete execution in a single step if evaluation confidence is high.  
    - Uses `logger.debug()` for all logging operations to avoid runtime errors with non-existent logger methods.

*   **Tool Layer (`src/mcp/`, `src/tools/`, `data/tools/`, `data/mcp-servers/`, `data/remote-mcp-servers/`)**:  
    - Provides the agent's capabilities via tools, which may be local scripts, local MCP servers, or remote MCP servers accessed via SDK.  
    - Tools follow a standard interface with `name`, `description`, and `execute()` method.  
    - `MCPToolManager` acts as the central registry and loader for all tools, supporting dynamic loading from local files, local MCP servers (via `MCPClient`), and remote MCP servers (via SDK).  

*Communication between layers is achieved through interfaces, event system (`sharedEventEmitter`), and standard protocols.*

## 2. Memory System

The Memory subsystem has been significantly refined with recent insights:

* **Storage Locations**:  
    - **Short-term memory (`short_term.txt`)**: Session-based, stores recent interactions, commands, intermediate results, tagged explicitly with module identifiers and timestamps. Content is appended with `<MEMORY>` tags, including context, module, and timestamp. Recent interactions like consolidation commands are stored as explicit commands with tags and timestamps, enabling targeted retrieval and analysis.  
    - **Long-term memory (`long_term.txt`)**: Persistent store for contextual info, summaries, and tags. When storing, an LLM analyzes content to generate summaries and relevance tags (`MEMORY_ANALYSIS_PROMPT`). When retrieving, relevance filtering is performed using an LLM-based relevance filtering prompt (`MEMORY_RETRIEVAL_PROMPT`).  

* **Memory Analysis & Categorization**:  
    - Recent interactions like consolidation commands are explicitly stored with module tags and timestamps.  
    - Memory analysis (summarization, tagging) is performed via LLM, and insights are stored in long-term memory, which informs future planning and responses.  
    - Commands such as memory consolidation, consolidation feedback, and memory analysis are explicitly recorded in memory logs, facilitating targeted queries and operations.  
    - Reflection prompts analyze the latest short-term memory and relevant long-term memory to generate JSON insights, lessons, follow-up questions, and directives.  
    - Reflection results, including lessons learned, are stored in long-term memory, feeding into the agent’s adaptive capabilities.

* **Memory Operations**:  
    - Emission of `subsystemMessage` events during memory retrieval, analysis, and storage for transparency.  
    - Memory data—including commands and their results—are available for analysis during reflection and consolidation commands, ensuring continuous learning and memory management.

## 3. System Flow & Operational Loop

The core operation is an iterative loop involving:

1. **User Input**: Incoming message via WebSocket or other interface.  
2. **Ego Processing (`Ego.processMessage`)**:  
    - Stores message in short-term memory with module tags.  
    - Retrieves relevant short-term and long-term memories via LLM relevance filtering and summarization.  
    - Creates an `enrichedMessage` containing user query, context, memories, and capabilities.  
3. **Planning (`Planner`)**:  
    - Builds a detailed prompt including `enrichedMessage`, available tools, short-term and relevant long-term memories.  
    - Calls the OpenAI API (with `PLAN_SCHEMA`) to generate a structured, JSON plan specifying steps and tools.  
    - Validates plan tools against available tools.  
    - Emits subsystem message with planning details.  
4. **Execution (`Coordinator`)**:  
    - Executes plan step-by-step, invoking tools via `MCPToolManager`.  
    - Handles errors, retries, or replans as necessary.  
    - Emits subsystem messages with execution results or errors.  
5. **DmemoryMaintenance Memory Maintenance (`memoryMaintenance` tool)**:  
    - Periodically or when explicitly scheduled, the planner invokes the heavy-weight `memoryMaintenance` tool.  
    - It consolidates long-term memory, prunes low-value items, and can run intensive evaluations of recent execution results where needed.  
6. **Decision & Retry**:  
    - If success score exceeds threshold (e.g., 80%) or max retries reached, proceed.  
    - If low score and retries remain, generate reflection prompts to analyze evaluation feedback, store lessons, and update context.  
7. **Response Generation (`Ego.handleBubble`)**:  
    - Uses LLM to transform internal tool execution results into natural, personality-driven responses to the user.  
    - Processes structured execution results which may be in one of three formats:
      - Error messages ("Error: [error message]")
      - Tool output content (plain text or JSON)
      - Complex objects with fields like type, response, and enriched_message
    - Generates responses that could be statements, summaries from results, or questions for the user.
    - The response output is formatted as JSON with 'chat' (brief 1-2 sentence response) and 'canvas' (detailed markdown content) fields.
    - Stores the response in memory.
    - Initiates reflection process after response, analyzing recent interactions and insights, storing lessons in long-term memory.  
8. **Output**: Response sent back to user, and process repeats if needed.

Throughout, status updates, debug info, and internal insights are emitted via `sharedEventEmitter`.

## 4. Reflection & Memory Enrichment

- The `reflection` tool analyzes the latest short-term memory and relevant long-term memory to generate JSON insights, lessons, follow-up questions, and directives.  
- These insights are stored in long-term memory, enhancing the agent’s adaptive capabilities.  
- Reflection occurs after each assistant response via the `reflection` tool, including during consolidation commands.  
- Reflection results include lessons learned, which inform future planning and decision-making.

## 5. Tools & Communication

- **`MCPToolManager`**: Registry and loader for local scripts, MCP servers, and remote MCP servers.  
- **`MCPClient`**: Handles communication with MCP servers, supports streaming responses for remote servers.  
- **Tools**: All tools conform to a uniform interface with `name`, `description`, and `execute()` method.  
- **Remote tools**: Accessed via SDK or local MCP servers, with communication managed through `MCPClient`.

## 6. Event System

- Key events include: `assistantResponse`, `debugResponse`, `systemStatusMessage`, `subsystemMessage`, `systemError`, and `bubble`.  
- These provide transparency, debugging, and insights into internal processes, especially memory operations, planning, execution, and reflection.

## 7. Configuration & Overrides

- Prompts can be overridden via files in `data/prompts/<module>/<PROMPT_NAME>.txt`.  
- Environment variables (`LLM_AGENT_DATA_DIR`, `API keys`) control data storage and API access.  
- Tool configurations are in `data/mcp-servers/` and `data/remote-mcp-servers/`.  
- Token limits are enforced via the `tokenLimit` setting (default: 10000 tokens). If a request exceeds this limit, an error is emitted to the error subsystem and the request is rejected.

## 8. Tool Parameter Handling in REACT Implementation

The REACT execution loop in the coordinator module implements special handling for tool parameters to ensure proper execution:

* **Parameter Mapping**: The system correctly maps parameters from the planner's output to the format expected by each tool.
* **Tool-Specific Requirements**: Different tools may have different parameter requirements. For example:
  - The `question` tool requires parameters in the format `{ question: "query text" }` rather than `{ query: "query text" }`.
  - The `llmquery` tool (with internet access) is used for real-time data queries and requires proper formatting.
* **Error Handling**: If a tool execution results in an error due to parameter issues, the error is logged and the execution continues to the next iteration.
* **Parameter Validation**: The system validates that required parameters are present before tool execution.
* **Fallback Behavior**: When parameters are missing or incorrectly formatted, the system attempts to provide meaningful error messages and continue execution when possible.

## 9. Recent Memory Insights & Operational Enhancements

- Memory analysis via LLM (summaries, tags) integrated into long-term storage.  
- Memory relevance filtering incorporates recent short-term context, providing richer, contextual retrieval.  
- Reflection after each response improves agent adaptability, with lessons stored for future cycles.  
- Explicit handling of commands like consolidation, consolidation feedback, and memory analysis has been integrated into operational flow.  
- Commands such as "consolidate" are explicitly stored as memory entries with module tags and timestamps, allowing targeted retrieval and processing.

---

## 9. Contradictions & Preferences

- The current detailed architecture has been refined with recent memory data.  
- Memory analysis, relevance-based retrieval, and reflection have been explicitly incorporated into the operational flow.  
- No contradictions were found; newer insights about explicit memory tagging, reflection, and memory analysis are now embedded.

---

This completes the comprehensive update of the technical model, integrating recent memory-driven insights to accurately reflect the current system operations, components, and operational flow.